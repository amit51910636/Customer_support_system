{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvhDEGve6OgY1PfdqNAiTU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amit51910636/Customer_support_system/blob/master/async_practical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eazrhmj8-6Vl",
        "outputId": "62e78fd9-0f2c-4dc5-e213-d7a41948928e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the breakfast maker!\n",
            "Starting the coffee brewing process...\n",
            "Coffee is ready!\n",
            "Starting to toast the bread...\n",
            "Bread is toasted!\n",
            "Breakfast is ready! Enjoy your meal!\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def brew_coffee():\n",
        "    print(\"Starting the coffee brewing process...\")\n",
        "    time.sleep(2)  # Wait 2 seconds to simulate brewing\n",
        "    print(\"Coffee is ready!\")\n",
        "\n",
        "def toast_bread():\n",
        "    print(\"Starting to toast the bread...\")\n",
        "    time.sleep(3)  # Wait 3 seconds to simulate toasting\n",
        "    print(\"Bread is toasted!\")\n",
        "\n",
        "def main():\n",
        "    print(\"Welcome to the breakfast maker!\")\n",
        "\n",
        "    # Start brewing coffee\n",
        "    brew_coffee()\n",
        "\n",
        "    # Start toasting bread\n",
        "    toast_bread()\n",
        "\n",
        "    print(\"Breakfast is ready! Enjoy your meal!\")\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import time\n",
        "\n",
        "async def async_brew_coffee():\n",
        "    print(\"Starting the coffee brewing process asynchronously...\")\n",
        "    await asyncio.sleep(2)  # Simulate time taken to brew coffee\n",
        "    print(\"Coffee is ready!\")\n",
        "\n",
        "async def async_toast_bread():\n",
        "    print(\"Starting to toast the bread asynchronously...\")\n",
        "    await asyncio.sleep(3)  # Simulate time taken to toast bread\n",
        "    print(\"Bread is toasted!\")\n",
        "\n",
        "async def main_async():\n",
        "    print(\"Welcome to the asynchronous breakfast maker!\")\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Run both tasks concurrently\n",
        "    await asyncio.gather(\n",
        "        async_brew_coffee(),\n",
        "        async_toast_bread()\n",
        "    )\n",
        "\n",
        "    end = time.time()\n",
        "    total_time = end - start\n",
        "    print(f\"Total time taken for breakfast preparation: {total_time:.2f} seconds\")\n",
        "\n",
        "    print(\"Breakfast is ready! Enjoy your meal!\")\n",
        "\n",
        "# Run the async main\n",
        "await main_async()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF6EPff-_GHE",
        "outputId": "5aaff94c-7733-447f-af0d-1fd721435ac0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the asynchronous breakfast maker!\n",
            "Starting the coffee brewing process asynchronously...\n",
            "Starting to toast the bread asynchronously...\n",
            "Coffee is ready!\n",
            "Bread is toasted!\n",
            "Total time taken for breakfast preparation: 3.00 seconds\n",
            "Breakfast is ready! Enjoy your meal!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()  # Loads environment variables from a .env file\n",
        "\n",
        "api_key = os.getenv('OPENAI_API_KEY')  # Retrieves the API key\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "pBE2a0uzAPiG",
        "outputId": "c9a641e7-8eff-4ce6-8bf8-573c1569b354"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'autogen_agentchat'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0ee7edff1ca4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen_agentchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAssistantAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIChatCompletionClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdotenv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autogen_agentchat'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\", api_key=api_key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "s3vkUiQtBL3l",
        "outputId": "243fe4b6-249f-4155-e254-71ac3c607c75"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'OpenAIChatCompletionClient' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6b7ab8dc5081>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIChatCompletionClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'OpenAIChatCompletionClient' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = AssistantAgent(name=\"assistant\", model_client=model_client)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "W8SFC8NPBSYp",
        "outputId": "1dd48861-8add-4649-ebed-64bc81b8e06f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AssistantAgent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1abc3bc09290>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0massistant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAssistantAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'AssistantAgent' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = await assistant.run(task=\"What is the capital of France?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "kRiVF_VpBjKh",
        "outputId": "520dc357-f947-4c32-efc8-8af8aecd7c47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'assistant' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-20cb49dfcbd9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0massistant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"What is the capital of France?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'assistant' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assistant_2 = AssistantAgent(\n",
        "    name='assistant',\n",
        "    model_client=model_client,\n",
        "    description=\"Give output in JSON\",\n",
        "    system_message=\"You are a helpful assistant that provides accurate information about history.\"\n",
        ")\n",
        "\n",
        "result = await assistant_2.run(task=\"What is the capital of France?\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "xnRx6QfPBkm9",
        "outputId": "ac4e09b4-882d-4962-91ca-2f4b7fe2c783"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AssistantAgent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6bd3df525996>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m assistant_2 = AssistantAgent(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'assistant'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Give output in JSON\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msystem_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"You are a helpful assistant that provides accurate information about history.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AssistantAgent' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.messages[-1].content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "xAGJm8dEB_3W",
        "outputId": "7094b65e-8184-43df-ddd4-1640cddb4153"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-04a9584e6a6e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multimodel message"
      ],
      "metadata": {
        "id": "RO-IK1tgCPLW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "import requests\n",
        "from autogen_agentchat.messages import MultiModalMessage\n",
        "from autogen_core import Image as AGImage\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Download image and convert to PIL image\n",
        "url = \"https://picsum.photos/id/237/200/300\"\n",
        "response = requests.get(url)\n",
        "pil_image = Image.open(BytesIO(response.content))\n",
        "\n",
        "# Step 2: Convert PIL image to AGImage\n",
        "img = AGImage(pil_image)\n",
        "\n",
        "# Step 3: Create a multimodal message with the image and a prompt\n",
        "multi_modal_message = MultiModalMessage(\n",
        "    content=[\"Can you describe the content of this image?\", img],\n",
        "    source=\"User\"\n",
        ")\n",
        "\n",
        "# Optional: Display or return the message\n",
        "print(multi_modal_message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "GD5Ok5VhGubN",
        "outputId": "73ca712e-488f-40cb-e501-d1b6766f81c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/requests/compat.py:48: RuntimeWarning: coroutine 'main_async' was never awaited\n",
            "  import simplejson as json\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'autogen_agentchat'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-15e24a1ec232>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen_agentchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiModalMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAGImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autogen_agentchat'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_model_message = MultiModalMessage(\n",
        "    content = ['What is there in the image?', img],\n",
        "    source = \"User\"\n",
        ")\n",
        "\n",
        "result = await assistant_2.run(task=multi_model_message)\n",
        "print(result.messages[-1].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ITdtsTThGu7c",
        "outputId": "bf1e9696-c073-4b96-e365-ff00157ff495"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MultiModalMessage' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d4aed2451c1d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m multi_model_message = MultiModalMessage(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'What is there in the image?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"User\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MultiModalMessage' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0BlRiLwTG0Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_a_JZQn_B0NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kBE6NGDQAI7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give me 5 line program to test openai key  and ask a question(What is capital of france)- from google.colab import userdata\n",
        "# userdata.get('secretName')\n",
        "\n",
        "!pip install openai\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get your OpenAI API key from Colab secrets\n",
        "openai.api_key = userdata.get('openai')\n",
        "\n",
        "try:\n",
        "  # Test the API key by making a simple request\n",
        "  response = openai.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
        "  )\n",
        "  print(\"OpenAI API key is valid!\")\n",
        "  print(\"Capital of France:\", response.choices[0].message.content)\n",
        "except Exception as e:\n",
        "  print(f\"Error testing OpenAI API key: {e}\")\n",
        "  print(\"Please check if your API key is correct and has the necessary permissions.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hhm_YYd_--a",
        "outputId": "f6020c44-64c1-477d-bc3c-0fe0f2dcf880"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.81.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Error testing OpenAI API key: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Please check if your API key is correct and has the necessary permissions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6BPYPbUyIpqX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}